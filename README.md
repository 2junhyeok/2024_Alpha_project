# Self Supervised Learning for Video Anomaly Detection

## Overview
ì´ í”„ë¡œì íŠ¸ëŠ” Jigsaw Learningì„ í™œìš©í•œ ë¹„ë””ì˜¤ ì´ìƒ íƒì§€(Video Anomaly Detection) ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì‹œê³µê°„ì  íŠ¹ì§•ì„ í•™ìŠµí•˜ì—¬ ë¹„ë””ì˜¤ ë‚´ì˜ ì´ìƒ í–‰ë™ì„ ê°ì§€í•©ë‹ˆë‹¤.

## Method
### Core Concepts
* ê¸°ì¡´ Jigsaw-VADëŠ” ë¼ë²¨ì´ ì—†ëŠ” ë¹„ë””ì˜¤ ë°ì´í„°ì—ì„œ ë¹„ì •ìƒì ì¸ ì´ë²¤íŠ¸ë¥¼ íƒì§€í•˜ê¸° ìœ„í•´ì„œ, ê³µê°„ì  ì§ì†Œ í¼ì¦ê³¼ ì‹œê°„ì  ì§ì†Œ í¼ì¦ì„ í•´ê²°í•˜ëŠ” pretext taskë¥¼ ì„¤ê³„
* ê·¸ëŸ¬ë‚˜ Frame ë‹¨ìœ„ì—ì„œë§Œ Anomalyë¥¼ ì§„í–‰í•˜ì—¬ ì •ì ì¸ ì´ìƒì¹˜ë‚˜, long-termì— ì·¨ì•½í•¨
* ì´ë¥¼ í•´ê²°í•˜ê³ ì Frame ë‹¨ìœ„ ì‹œê³µê°„ Jigsawì— Clip ë‹¨ìœ„ê¹Œì§€ í™•ì¥í•˜ì—¬ DADì— ì ìš©í•¨

### Key Features
* **Clip ë‹¨ìœ„ Spatial**
  * ê¸°ì¡´ì˜ spatialì€ í•œ ì¥ì˜ Frameì„ ëŒ€ìƒìœ¼ë¡œ 9ê°œì˜ ì¡°ê°ì„ ë§Œë“¤ì–´ í•™ìŠµì„ ì§„í–‰í–ˆì§€ë§Œ, ë³¸ ì—°êµ¬ì—ì„œëŠ” Clip ìì²´ë¥¼ 9ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´, ê¸´ time stepì„ ê³ ë ¤í•œ Clip ë‹¨ìœ„ Spatialì„ í•™ìŠµí•¨
* **Clip ë‹¨ìœ„ Temporal**
  * ê¸°ì¡´ì˜ Temporalì€ 7ì¥ì˜ Frameì„ ëŒ€ìƒìœ¼ë¡œ ìˆœì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ì„œ ìˆœì„œë¥¼ ë§ì¶”ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í–ˆì§€ë§Œ, ë³¸ ì—°êµ¬ì—ì„œëŠ” 7ì¥ì˜ Frameì´ ë‹´ê¸´ Clipì„ ëŒ€ìƒìœ¼ë¡œ ìˆœì„œë¥¼ ë§ì¶”ëŠ” ë°©ì‹ìœ¼ë¡œ ê¸´ time stepë„ í•™ìŠµí•¨
* **4ê°œì˜ Predictor**
  * Frame ë‹¨ìœ„ì™€ Clip ë‹¨ìœ„ ê°ê°ì˜ Spatialê³¼ Temporalì´ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— 4ê°€ì§€ ì¶œë ¥ì„ ìƒì„±í•˜ë„ë¡ í•™ìŠµì„ ì§„í–‰í•¨
* **Lossë¥¼ ê³µìœ í•˜ëŠ” Backbone**
  * Frame ë‹¨ìœ„ì™€ Clip ë‹¨ìœ„ëŠ” ì…ë ¥ì˜ í˜•íƒœê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ë‘ ê°€ì§€ Taskë¥¼ ë™ì‹œì— í•™ìŠµí•˜ê¸° ìœ„í•´ì„œëŠ” Backboneì„ ê³µìœ í•˜ë©´ì„œ Lossë¥¼ ê³µìœ í•˜ëŠ” ë°©ì‹ì˜ í•™ìŠµì„ ì§„í–‰í•¨

## Project Structure
```
ğŸ“¦ Video-Anomaly-Detection
â”œâ”€â”€ ğŸ“‚ models/               # Model implementation files
â”œâ”€â”€ ğŸ“‚ tool/                # Utility tools
â”œâ”€â”€ ğŸ“„ aggregate.py         # Result aggregation and evaluation
â”œâ”€â”€ ğŸ“„ data_preprocessing.py # Data preprocessing
â”œâ”€â”€ ğŸ“„ dataset.py           # Dataset class implementation
â”œâ”€â”€ ğŸ“„ gen_patches.py       # Patch generation
â”œâ”€â”€ ğŸ“„ generate_frame_mask.py # Frame mask generation
â”œâ”€â”€ ğŸ“„ main.py             # Main execution file
â”œâ”€â”€ ğŸ“„ pkl.py              # Pickle file processing
â””â”€â”€ ğŸ“„ restructure_dataset.py # Dataset structure reorganization
```

## Technical Requirements

### requirements
```bash
torch
torchvision
numpy
opencv-python
scipy
tqdm
```

## Dataset Structure
```
ğŸ“¦ DAD_Jigsaw
â”œâ”€â”€ ğŸ“‚ training/
â”‚   â”œâ”€â”€ ğŸ“‚ front_depth/
â”‚   â”œâ”€â”€ ğŸ“‚ front_IR/
â”‚   â”œâ”€â”€ ğŸ“‚ top_depth/
â”‚   â””â”€â”€ ğŸ“‚ top_IR/
â””â”€â”€ ğŸ“‚ testing/
    â”œâ”€â”€ ğŸ“‚ front_depth/
    â”œâ”€â”€ ğŸ“‚ front_IR/
    â”œâ”€â”€ ğŸ“‚ top_depth/
    â””â”€â”€ ğŸ“‚ top_IR/
```

## Installation Guide

1. Clone Repository
```bash
git clone https://github.com/yugwangyeol/Self-Supervised-Learning-for-Video-Anomaly-Detection.git
cd Self-Supervised-Learning-for-Video-Anomaly-Detection
```

2. Install Dependencies
```bash
pip install -r requirements.txt
```

3. Setup Dataset Structure
```bash
python restructure_dataset.py
```

## Execution Guide

### 1. Data Preprocessing
```bash
python data_preprocessing.py
```

### 2. Frame Mask Generation
```bash
python generate_frame_mask.py
```

### 3. Model Training
```bash
python main.py --data_type top_depth --epochs 100 --batch_size 64
```

### 4. Evaluation
```bash
python aggregate.py --file [output_pkl_file] --dataset DAD_Jigsaw --frame_num [num_frames]
```

## Implementation Details

### Training Process
- Batch Size: 64
- Learning Rate: 1e-4
- Optimizer: Adam
- Loss Function: CrossEntropyLoss

## Experimental Results
![Image](https://github.com/user-attachments/assets/cee8ae5d-71cc-4f3c-9eb2-39661368e0c8)

* ì‹œê³µê°„ì  íŠ¹ì§•ì„ ë™ì‹œì— ê³ ë ¤í•˜ëŠ” ì´ì¤‘ ë¶„ì„ ì²´ê³„ë¥¼ í†µí•´ ì•ˆì •ì ì¸ ì´ìƒ íƒì§€ ì„±ëŠ¥ ë‹¬ì„±
* Driver Video Datasetì´ë¼ëŠ” ì„¸ë¶€ ë¶„ì•¼ì—ì„œ ì¤€ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨
* Self Supervised Learningì„ ë„ì…í•˜ì—¬ ë ˆì´ë¸”ì´ ìˆëŠ” ë°ì´í„° ì˜ì¡´ë„ë¥¼ ë‚®ì¶¤
* ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•œ íš¨ìœ¨ì ì¸ ì‹œìŠ¤í…œ êµ¬ì¡° í™•ë¦½
* ì‹¤ì œ ì°¨ëŸ‰ í™˜ê²½ì—ì„œì˜ ì¦‰ê°ì ì¸ ìœ„í—˜ê°ì§€ ì‹œìŠ¤í…œìœ¼ë¡œ í™œìš©ì´ ê°€ëŠ¥í•¨
* ë‹¤ì–‘í•œ ìš´ì „ì í™˜ê²½ì— ì ìš©í•  ìˆ˜ ìˆëŠ” í™•ì¥ì„± í™•ë³´
* ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ì˜ í†µí•©ì´ ì‰¬ìš´ ëª¨ë“ˆí™”ëœ êµ¬ì¡°

## Conclusion
* ê¸°ì¡´ ëª¨ë¸ì— ë¹„í•´ í—ˆìš© ê°€ëŠ¥í•œ ì˜¤ì°¨ ë‚´ì—ì„œ ë¹„ìŠ·í•œ ì„±ëŠ¥
* ì œì•ˆí•œ ëª¨ë¸ì€ ë°ì´í„°ì— ëŒ€í•´ ì‹œê°„ì , ê³µê°„ì  íŠ¹ì§•ì„ ë”ìš± ë‹¤ì–‘í•˜ê²Œ ì´í•´ ê°€ëŠ¥
* combined ê²°ê³¼ê°€ ì‹¤ì œ ì ìš© ì‹œì—ëŠ” ë” ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆìœ¼ë¦¬ë¼ íŒë‹¨

## Contributors
ì†Œì†: êµ­ë¯¼ëŒ€í•™êµ AIë¹…ë°ì´í„°ìœµí•©ê²½ì˜í•™ê³¼ Alpha Project  

íŒ€ì›: ìœ ê´‘ì—´, ê¹€ì„œë ¹, ì´ì¤€í˜

## Ciation
```BiTex
@inproceedings{wang2022jigsaw-vad,
  title     = {Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles},
  author    = {Guodong Wang and Yunhong Wang and Jie Qin and Dongming Zhang and Xiuguo Bao and Di Huang},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2022}
}
```
